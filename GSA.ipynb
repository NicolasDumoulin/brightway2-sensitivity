{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global ensitivity Analysis\n",
    "## Project initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-23T11:27:56.624736",
     "start_time": "2017-03-23T11:27:55.973506"
    }
   },
   "outputs": [],
   "source": [
    "from brightway2 import *\n",
    "from __future__ import unicode_literals, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-23T11:27:56.638118",
     "start_time": "2017-03-23T11:27:56.626365"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "projects.set_current(\"Global Sensitivity Analysis demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding some uncertainties in sample data (from [this notebook](http://nbviewer.jupyter.org/urls/bitbucket.org/cmutel/brightway2/raw/default/notebooks/Getting%20Started%20with%20Brightway2.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-23T11:27:56.642840",
     "start_time": "2017-03-23T11:27:56.639829"
    }
   },
   "outputs": [],
   "source": [
    "bw2setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-23T11:28:10.216750",
     "start_time": "2017-03-23T11:27:56.645080"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from bw2data.utils import download_file\n",
    "\n",
    "filepath = download_file(\"forwast.bw2package.zip\", url=\"http://lca-net.com/wp-content/uploads/\")\n",
    "dirpath = os.path.dirname(filepath)\n",
    "zipfile.ZipFile(filepath).extractall(dirpath)\n",
    "BW2Package.import_file(os.path.join(dirpath, \"forwast.bw2package\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-23T11:28:17.138436",
     "start_time": "2017-03-23T11:28:10.218359"
    }
   },
   "outputs": [],
   "source": [
    "from bw2data.utils import uncertainify\n",
    "from stats_arrays import NormalUncertainty\n",
    "uncertain_db = Database(\"forwast uncertain +\")\n",
    "uncertain_db.write(\n",
    "    uncertain_db.relabel_data(\n",
    "        uncertainify(\n",
    "            Database(\"forwast\").load(), \n",
    "            NormalUncertainty\n",
    "        ), \n",
    "        \"forwast uncertain +\" \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-23T15:17:19.833396",
     "start_time": "2017-03-23T15:17:19.807505"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method_key=('ReCiPe Endpoint (I,A)', 'ecosystem quality', 'total')#'IMPACT 2002+ (Endpoint)', 'climate change', 'total')\n",
    "activity = uncertain_db.search('Wood products EU27')[0]\n",
    "lca = LCA({activity: 1}, method_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random initialization\n",
    "Initialization of the RNG stuff in the same way that in the MonteCarloLCA class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-23T15:17:21.021296",
     "start_time": "2017-03-23T15:17:20.859808"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lca.load_lci_data()\n",
    "from stats_arrays.random import MCRandomNumberGenerator\n",
    "tech_rng = MCRandomNumberGenerator(lca.tech_params)\n",
    "bio_rng = MCRandomNumberGenerator(lca.bio_params)\n",
    "lca.load_lcia_data()\n",
    "cf_rng = MCRandomNumberGenerator(lca.cf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-23T15:17:25.347112",
     "start_time": "2017-03-23T15:17:21.984229"
    }
   },
   "outputs": [],
   "source": [
    "from lsa import lsa\n",
    "rsca_summary, rscb_summary = lsa(lca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binding RSC results and uncertainties\n",
    "The local sensitivity analysis give us the indices of matrices A and B that have the more relevant RSC (relative sensitivity coefficients). The purpose is now to fetch the associated uncertainties from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A_indices = np.array(np.array(rsca_summary)[:,1:3],int).tolist()\n",
    "B_indices = np.array(np.array(rscb_summary)[:,1:3],int).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fetch these uncertainties in the attributes `tech_params` and `bio_params` of the LCA object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "tech_df = DataFrame.from_records(lca.tech_params)\n",
    "bio_df = DataFrame.from_records(lca.bio_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for example at the uncertainties of the first sensible element for the matrix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_df[(tech_df.row==A_indices[0][0]) & (tech_df.col==A_indices[0][1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we get more than one element, because we should consider the column `type` which is defined in the [utils.py module](https://bitbucket.org/cmutel/brightway2-calc/src/105e24e2d803c96773651ed73c43d850f9c23548/bw2calc/utils.py?at=default&fileviewer=file-view-default#utils.py-144) as follow:\n",
    "```\n",
    "    TYPE_DICTIONARY = {\n",
    "        \"unknown\": -1,\n",
    "        \"production\": 0,\n",
    "        \"technosphere\": 1,\n",
    "        \"biosphere\": 2,\n",
    "        \"substitution\": 3,\n",
    "    }\n",
    "```\n",
    "This ```field``` attribute is setted during the matices building process in the class ```TechnosphereBiosphereMatrixBuilder``` of the [module matrices.py](https://bitbucket.org/cmutel/brightway2-calc/src/105e24e2d803c96773651ed73c43d850f9c23548/bw2calc/matrices.py?at=default&fileviewer=file-view-default#matrices.py-176).\n",
    "\n",
    "So, we can restrict to the row with the concerned type, and we get the ```minimum``` and ```maximum``` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_df[(tech_df.type==1) & (tech_df.row==A_indices[0][0]) & (tech_df.col==A_indices[0][1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fixme](https://www.dokuwiki.org/lib/images/smileys/fixme.gif)\n",
    "But for some element, we can't find minimum and maximum values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A_indices[6])\n",
    "tech_df[(tech_df.row==A_indices[6][0]) & (abs(tech_df.col-A_indices[6][1])<4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_A = [a for a in A_indices if len(tech_df[(tech_df.type==1) & (tech_df.row==a[0]) & (tech_df.col==a[1])])==0]\n",
    "errors_B = [b for b in B_indices if len(bio_df[(bio_df.type==2) & (bio_df.row==b[0]) & (bio_df.col==b[1])])==0]\n",
    "print(\"Errors for A: {}/{} {}\".format(len(errors_A), len(A_indices), errors_A))\n",
    "print(\"Errors for B: {}/{} {}\".format(len(errors_B), len(B_indices), errors_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fixme](https://www.dokuwiki.org/lib/images/smileys/fixme.gif)\n",
    "Dirty solution for patching the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A_indices = [a for a in A_indices if len(tech_df[(tech_df.type==1) & (tech_df.row==a[0]) & (tech_df.col==a[1])])>0]\n",
    "B_indices = [b for b in B_indices if len(bio_df[(bio_df.type==2) & (bio_df.row==b[0]) & (bio_df.col==b[1])])>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the problem data\n",
    "Here, we want to define the parameters to sample using a list of selected elements of the biosphere and technosphere matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-24T15:57:25.694627",
     "start_time": "2017-03-24T15:57:25.585116"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#A_indices = np.array(np.array(rsca_summary)[:6,1:3],int).tolist()\n",
    "#B_indices = np.array(np.array(rscb_summary)[:6,1:3],int).tolist()\n",
    "rev_activity, rev_product, rev_bio = lca.reverse_dict()\n",
    "morris_problem = {\n",
    "    'num_vars':len(A_indices)+len(B_indices),\n",
    "    'names':[],\n",
    "    'bounds':[],\n",
    "    'groups':None\n",
    "}\n",
    "morris_problem['names'] += [\n",
    "    'Technosphere '+ str(Database(rev_activity[x[0]][0]).get(rev_activity[x[0]][1])) + ' x ' + str(Database(rev_product[x[1]][0]).get(rev_product[x[1]][1]))\n",
    "    for x in A_indices\n",
    "    ]\n",
    "morris_problem['names'] += [\n",
    "    'Biosphere '+str(Database(rev_bio[x[0]][0]).get(rev_bio[x[0]][1])) + ' x ' + str(Database(rev_activity[x[1]][0]).get(rev_activity[x[1]][1]))\n",
    "    for x in B_indices\n",
    "    ]\n",
    "# retrieve min and max values for populating morris_problem['bounds']\n",
    "from pandas import DataFrame\n",
    "tech_df = DataFrame.from_records(lca.tech_params)\n",
    "bio_df = DataFrame.from_records(lca.bio_params)\n",
    "morris_problem['bounds'] = [tech_df[(tech_df.type==1) & (tech_df.row==a_ij[0]) & (tech_df.col==a_ij[1])][['minimum','maximum']].values[0] for a_ij in A_indices] + [bio_df[(bio_df.type==2) & (bio_df.row==b_ij[0]) & (bio_df.col==b_ij[1])][['minimum','maximum']].values[0] for b_ij in B_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Sobol indices\n",
    "\n",
    "### Multiprocessing class\n",
    "This class will generate the Morris sample and perform lcia computations using multiprocessing feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-24T15:20:54.450061",
     "start_time": "2017-03-24T15:20:54.403235"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from SALib.sample import morris as ms\n",
    "from SALib.analyze import morris as ma\n",
    "import multiprocessing\n",
    "import pyprind\n",
    "import math\n",
    "\n",
    "class ParallelGSALCA:\n",
    "    def __init__(self, demand, method, morris_problem):\n",
    "        self.demand = demand\n",
    "        self.method = method\n",
    "        # TODO generate morris_problem instead of parameter\n",
    "        self.morris_problem = morris_problem\n",
    "    def single_worker(self, sample):\n",
    "        '''\n",
    "        Computes the lcia impacts for the given data sampling corresponding to the initial morris problem.\n",
    "        Returns an array containing the aggregated score and then the impacts for each category.\n",
    "        '''\n",
    "        lca = LCA(self.demand, self.method)\n",
    "        lca.load_lci_data()\n",
    "        if lca.lcia:\n",
    "            lca.load_lcia_data()\n",
    "        if lca.weighting:\n",
    "            lca.load_weighting_data            \n",
    "        for a_ij, value in zip(self.A_indices, sample[:len(self.A_indices)]):\n",
    "            #print('aij',tuple(a_ij),value, lca.technosphere_matrix[tuple(a_ij)])\n",
    "            lca.technosphere_matrix[tuple(a_ij)] = value\n",
    "            #print(lca.technosphere_matrix[tuple(a_ij)])\n",
    "        for b_ij, value in zip(self.B_indices, sample[len(self.A_indices):]):\n",
    "            #print('bij',tuple(b_ij),value)\n",
    "            lca.biosphere_matrix[tuple(b_ij)] = value\n",
    "        if not hasattr(lca, \"demand_array\"):\n",
    "            lca.build_demand_array()\n",
    "        import warnings\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            lca.lci_calculation()\n",
    "        if lca.lcia:\n",
    "            lca.lcia_calculation()\n",
    "        return np.concatenate(([lca.score], np.array(lca.characterized_inventory.sum(axis=1).ravel())[0]))\n",
    "    def gsa(self, A_indices, B_indices, number_of_trajectories, progressBar=True, cpus=None, chunk_size=None):\n",
    "        '''\n",
    "        Samples the A and B element using Morris method and return the computed impact\n",
    "        for the aggregated score and then for each category of impact.\n",
    "        '''\n",
    "        self.A_indices = A_indices\n",
    "        self.B_indices = B_indices\n",
    "        cpus = cpus or multiprocessing.cpu_count()\n",
    "        # TODO propose an automatic number_of_trajectories\n",
    "        self.samples = ms.sample(self.morris_problem, number_of_trajectories, num_levels=4, grid_jump=2)\n",
    "        if chunk_size:\n",
    "            self.chunk_size = chunk_size\n",
    "        else:\n",
    "            self.chunk_size = max(cpus, number_of_trajectories // 100)\n",
    "        pool = multiprocessing.Pool(processes=cpus)\n",
    "        if progressBar:\n",
    "            bar = pyprind.ProgBar(max(1,math.ceil(len(self.samples)/self.chunk_size)))\n",
    "        chunks = []\n",
    "        scores = [[] for i in range(1 + lca.characterization_matrix.shape[0])]\n",
    "        # store in 'stores' all the mid-point impact\n",
    "        for sample in self.samples:\n",
    "            chunks.append(sample)\n",
    "            if len(chunks) == self.chunk_size:\n",
    "                for i,result_by_impact in enumerate(map(list,zip(*pool.map(self.single_worker, chunks)))):\n",
    "                    scores[i] += result_by_impact\n",
    "                if progressBar:\n",
    "                    bar.update()\n",
    "                chunks=[]\n",
    "        if len(chunks):\n",
    "            for i,result_by_impact in enumerate(map(list,zip(*pool.map(self.single_worker, chunks)))):\n",
    "                scores[i] += result_by_impact\n",
    "            if progressBar:\n",
    "                bar.update()\n",
    "            chunks=[]\n",
    "        self.scores = scores\n",
    "        return scores\n",
    "    def gsa_analyse(self):\n",
    "        return [ma.analyze(self.morris_problem, self.samples, np.array(score), num_levels=4, grid_jump=2) for score in self.scores]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-24T15:22:23.971982",
     "start_time": "2017-03-24T15:21:02.626587"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gsalca = ParallelGSALCA({activity: 1}, method_key, morris_problem)\n",
    "scores = gsalca.gsa(A_indices, B_indices, number_of_trajectories = 100)#, progressBar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "Now, we can inspect the Sobol indices with the ```analyse``` method, for each category of impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-24T15:23:23.494225",
     "start_time": "2017-03-24T15:23:23.476342"
    }
   },
   "outputs": [],
   "source": [
    "analyse = gsalca.gsa_analyse()\n",
    "print(analyse[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, looking at sensitivity for the aggregated score (first element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_score=DataFrame(analyse[0])\n",
    "si_score[si_score['mu']!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivities for a category of impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=DataFrame(analyse[1])\n",
    "df[df['mu']!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing sensitivities on single score and categories\n",
    "We select the sensitivity indexes with highest ```mu``` values for single score, and we will look at the SI computed for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the category that have a sum of ```mu``` indices to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k,an in enumerate(analyse[1:]):\n",
    "    an['category']=k\n",
    "interesting_analyse = list(filter(lambda x:sum(abs(x['mu']))>0,analyse[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we plot the ```mu``` indices for each keeped category, and highlighting in red the indices of the process that gives the highest sensitivities on single score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsi_score_index = si_score.mu.abs().sort_values().index[-5:]\n",
    "hsi_score = si_score.reindex(hsi_score_index)\n",
    "fig, axes = plt.subplots(math.ceil((len(interesting_analyse))/3),3)\n",
    "for ax, si in zip(axes.flat, interesting_analyse):\n",
    "    rects = ax.bar(range(len(si['mu'])),abs(si['mu']), yerr=si['sigma'])\n",
    "    ax.set_title('Category {}'.format(si['category']))\n",
    "    for i,patch in enumerate(rects.patches):\n",
    "        if i in hsi_score_index:\n",
    "            patch.set_color('red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsi_score_index = si_score.mu_star.abs().sort_values().index[-5:]\n",
    "hsi_score = si_score.reindex(hsi_score_index)\n",
    "fig, axes = plt.subplots(math.ceil((len(interesting_analyse))/3),3)\n",
    "for ax, si in zip(axes.flat, interesting_analyse):\n",
    "    rects = ax.bar(range(len(si['mu_star'])),abs(si['mu_star']), yerr=si['mu_star_conf'])\n",
    "    ax.set_title('Category {}'.format(si['category']))\n",
    "    for i,patch in enumerate(rects.patches):\n",
    "        if i in hsi_score_index:\n",
    "            patch.set_color('red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- Is the factor's selection pertinent after the LSA (threshold=0.1)?\n",
    "- Some missing uncertainties in section 1.5 (fixme). To see with Chris Mutel\n",
    "- Which is the best GSAÂ indicator among mu and mu_star? Are the errors relevant on the charts?\n",
    "- Produce a python module as lsa.py with an easy access to GSA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "104px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
